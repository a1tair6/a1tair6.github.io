# Hadoop 3.1.2 설치

- hadoop 3.1.2, hive 3.1.1, spark 2.4.2, tez 0.9.2, zookeeper 3.4.14
- instance aws ec2 ami
- name node 2ea
- data node 3ea
- type m5.xlarge

## Instance Setting
### java
#### 설치
`apt-get install openjdk-8-jdk`

#### 확인
`java -version`

### 계정 생성
`sudo adduser hadoop`
#### 비밀번호 설정
`passwd hadoop`

### ssh
#### 설치
`apt-get install openssh-server`

- public key 생성
`ssh-keygen -t rsa -P`

- 인증키로 등록
`cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`

- ssh 접속 확인
`ssh localhost`

- 전체 node에 namenode 2ea의 public key 등록
`vi ~/.ssh/authorized_keys` (copy & paste or rsync)

### host 파일 등록
```
X.X.X.X host-nn-01
X.X.X.X host-nn-02
X.X.X.X host-dn-01
X.X.X.X host-dn-02
X.X.X.X host-dn-03
```

### .bashrc config
```
export HADOOP_HOME="/home/hadoop/eco_service/hadoop"
export HADOOP_CONF_DIR="/home/hadoop/eco_service/hadoop/etc/hadoop"
export HIVE_HOME="/home/hadoop/eco_service/hive"
export SPARK_HOME="/home/hadoop/eco_service/spark"
export LD_LIBRARY_PATH="$HADOOP_HOME/lib/native"
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin:$SPARK_HOME/bin:$LD_LIBRARY_PATH
export PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH
export PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$PYTHONPATH
```

## zookeeper install
### zookeeper 3.4.14 binary download
```
cd /home/hadoop/installed
wget http://apache.tt.co.kr/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz
tar -xvf zookeeper-3.4.14.tar.gz
rm -rf zookeeper-3.4.14.tar.gz
ln -s /home/hadoop/installed/zookeeper-3.4.14 /home/hadoop/eco_service/zookeeper
```

### zookeeper config
```
cp /home/hadoop/eco_service/zookeeper/conf/zoo_sample.cfg /home/hadoop/eco_service/zookeeper/conf/zoo.cfg
vi /home/hadoop/eco_service/zookeeper/conf/zoo.cfg
```

### zoo.conf
```
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just
# example sakes.
dataDir=/home/hadoop/eco_service/zookeeper/data
# the port at which the clients will connect
clientPort=2181
# the maximum number of client connections.
# increase this if you need to handle more clients
maxClientCnxns=60
maxSessionTimeout=180000
#
# Be sure to read the maintenance section of the
# administrator guide before turning on autopurge.
#
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1
server.1=host-nn-001-01:2888:3888
server.2=host-nn-001-02:2888:3888
server.3=host-dn-001-01:2888:3888
```

### create zookeeper myid
```
namenode 1번
echo 1 > /home/hadoop/eco_service/zookeeper/data/myid
namenode 2번
echo 2 > /home/hadoop/eco_service/zookeeper/data/myid
datanode 1번
echo 3 > /home/hadoop/eco_service/zookeeper/data/myid
```

### run zookeeper
`home/hadoop/eco_service/zookeeper/bin/zkServer.sh start`


## hadoop install
- workdir은 /home/hadoop
- 설치된 package /home/hadoop/installed 밑에
- soft link 로 /home/hadoop/eco_service 밑에

### hadoop 3.1.2 binary download
```
cd /home/hadoop/installed
wget http://apache.tt.co.kr/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz
tar -xvf hadoop-3.1.2.tar.gz
rm -rf hadoop-3.1.2.tar.gz
ln -s /home/hadoop/installed/hadoop-3.1.2 /home/hadoop/eco_service/hadoop
```

### hadoop config
<details>
  <summary>capacity-scheduler.xml</summary>
  <p>

```
  <property>
    <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
    <value>0.7</value>
    <description>
      Maximum percent of resources in the cluster which can be used to run
      application masters i.e. controls number of concurrent running
      applications.
    </description>
  </property>
```
</p>
</details>

<details>
  <summary>hdfs-site.xml</summary>
  <p>

```
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/usr/local/hadoop/data/namenode</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/usr/local/hadoop/data/datanode</value>
  </property>
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/usr/local/hadoop/data/dfs/journalnode</value>
  </property>
  <property>
    <name>dfs.nameservices</name>
    <value>host-cluster</value>
  </property>
  <property>
    <name>dfs.ha.namenodes.host-cluster</name>
    <value>nn1,nn2</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.host-cluster.nn1</name>
    <value>host-nn-001-01:8020</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.host-cluster.nn2</name>
    <value>host-nn-001-02:8020</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.host-cluster.nn1</name>
    <value>host-nn-001-01:50070</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.host-cluster.nn2</name>
    <value>host-nn-001-02:50070</value>
  </property>
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://host-nn-001-01:8485;host-nn-001-02:8485;host-dn-001-01:8485/host-cluster</value>
  </property>
  <property>
    <name>dfs.client.failover.proxy.provider.host-cluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence
      <!-- shell(/bin/true) -->
    </value>
  </property>
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/hadoop/.ssh/id_rsa</value>
  </property>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <property>
  <name>dfs.webhdfs.enabled</name>
  <value>true</value>
</property>

<property>
  <name>dfs.permissions</name>
  <value>false</value>
</property>

</configuration>
```
  </p>
</details>


<details>
  <summary>core-site.xml</summary>
  <p>

```
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
       <name>fs.defaultFS</name>
        <value>hdfs://host-cluster</value>
    </property>

    <property>
        <name>ha.zookeeper.quorum</name>
        <value>host-nn-001-01:2181,host-nn-001-02:2181,host-dn-001-01:2181</value>
    </property>

    <property>
        <name>fs.trash.interval</name>
        <value>1440</value>
    </property>

    <property>
        <name>fs.trash.interval</name>
        <value>720</value>
    </property>

    <property>
        <name>hadoop.proxyuser.hadoop.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hadoop.groups</name>
        <value>*</value>
    </property>


    <property>
        <name>hadoop.proxyuser.hive.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hive.groups</name>
        <value>*</value>
    </property>


    <property>
        <name>hadoop.proxyuser.oozie.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.oozie.groups</name>
        <value>*</value>
    </property>

    <property>
        <name>hadoop.proxyuser.hue.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hue.groups</name>
        <value>*</value>
    </property>

    <property>
        <name>hadoop.proxyuser.admin.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.admin.groups</name>
        <value>*</value>
    </property>

    <property>
        <name>hadoop.proxyuser.root.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.root.groups</name>
        <value>*</value>
    </property>
        <property>
       <name>fs.s3a.access.key</name>
       <value>{access_key}</value>
       <description>AWS access key ID. Omit for Role-based authentication.</description>
    </property>
    <property>
       <name>fs.s3a.secret.key</name>
       <value>{secret key}</value>
       <description>AWS secret key. Omit for Role-based authentication.</description>
    </property>

    <property>
       <name>fs.s3a.endpoint</name>
       <value>s3.{region}.amazonaws.com</value>
    </property>
</configuration>
```
</p>
</details>

<details>
  <summary>mapred-site.xml</summary>
  <p>

```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>mapreduce.job.ubertask.enable</name>
        <value>true</value>
    </property>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/home/hadoop/eco_service/hadoop</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/home/hadoop/eco_service/hadoop</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/home/hadoop/eco_service/hadoop</value>
    </property>

    <property>
        <name>yarn.app.mapreduce.am.resource.mb</name>
        <value>7680</value>
    </property>

    <property>
        <name>mapreduce.map.memory.mb</name>
        <value>7680</value>
    </property>

    <property>
        <name>mapreduce.reduce.memory.mb</name>
        <value>7680</value>
    </property>

    <property>
        <name>mapreduce.map.java.opts.max.heap</name>
        <value>6144</value>
    </property>

    <property>
        <name>mapreduce.reduce.java.opts.max.heap</name>
        <value>6144</value>
    </property>

    <property>
        <name>yarn.nodemanager.vmem-check-enable</name>
        <value>false</value>
    </property>

    <property>
        <name>yarn.nodemanager.vmem-pmem-ratio</name>
        <value>4</value>
    </property>

    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>host-nn-001-01:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>host-nn-001-01:19888</value>
    </property>

    <property>
        <name>mapreduce.task.io.sort.mb</name>
        <value>3072</value>
    </property>

    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_CONF_DIR,
               $HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,
               $HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,
               $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,
               $HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*,
               $HADOOP_MAPRED_HOME/share/hadoop/tools/lib/*</value>
    </property>


</configuration>
```
</p>
</details>


<details>
  <summary>yarn-site.xml</summary>
  <p>

```
<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>

<!-- Site specific YARN configuration properties -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle,spark_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>
        <value>org.apache.spark.network.yarn.YarnShuffleService</value>
    </property>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/usr/local/hadoop/data/yarn/nm-local-dir</value>
    </property>
    <property>
        <name>yarn.resourcemanager.fs.state-store.uri</name>
        <value>/usr/local/hadoop/data/yarn/system/rmstore</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.resourcemanager.cluster-id</name>
        <value>rm-cluster</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.rm-ids</name>
        <value>rm1,rm2</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname.rm1</name>
        <value>host-nn-001-02</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname.rm2</name>
        <value>host-nn-001-01</value>
    </property>
    <property>
        <name>hadoop.zk.address</name>
        <value>host-nn-001-01:2181,host-nn-001-02:2181,host-dn-001-01:2181</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.client.failover-proxy-provider</name>
        <value>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider</value>
    </property>
    <property>
        <name>yarn.resourcemanager.store.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.automatic-failover.zk-base-path</name>
        <value>/yarn-leader-election</value>
    </property>
    <property>
        <name>yarn.resourcemanager.recovery.enabled</name>
        <value>true</value>
    </property>

    <property>
        <name>yarn.resourcemanager.address.rm1</name>
        <value>host-nn-001-02:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address.rm1</name>
        <value>host-nn-001-02:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address.rm1</name>
        <value>host-nn-001-02:8088</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address.rm1</name>
        <value>host-nn-001-02:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address.rm1</name>
        <value>host-nn-001-02:8033</value>
    </property>

    <property>
        <name>yarn.resourcemanager.address.rm2</name>
        <value>host-nn-001-01:8032</value>
    </property>
    <property>
           <name>yarn.resourcemanager.scheduler.address.rm2</name>
        <value>host-nn-001-01:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address.rm2</name>
        <value>host-nn-001-01:8088</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address.rm2</name>
        <value>host-nn-001-01:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address.rm2</name>
        <value>host-nn-001-01:8033</value>
    </property>

    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>23040</value>
    </property>

    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>8</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>7680</value>
    </property>

    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>23040</value>
    </property>

    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>false</value>
    </property>

    <property>
        <name>yarn.resourcemanager.nodes.include-path</name>
        <value>/home/hadoop/eco_service/hadoop/etc/hadoop/nodes_include</value>
    </property>

    <!--property>
        <name>yarn.nodemanager.aux-services.spark_shuffle.classpath</name>
        <value>/home/hadoop/eco_service/spark/yarn/*</value>
    </property-->

    <property>
        <name>yarn.log.server.url</name>
        <value>http://host-nn-001-01:19888/jobhistory/logs</value>
    </property>

    <property>
        <name>yarn.application.classpath</name>
        <value>$HADOOP_CONF_DIR,
               $HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,
               $HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,
               $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,
               $HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*,
               $HADOOP_YARN_HOME/share/hadoop/tools/lib/*</value>
    </property>

    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```
</p>
</details>

<details>
  <summary>hadoop-env.sh</summary>
  <p>

```
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-0.amzn2.x86_64
export HADOOP_HOME=/home/hadoop/eco_service/hadoop
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HADOOP_OS_TYPE=${HADOOP_OS_TYPE:-$(uname -s)}
export TEZ_HOME=/home/hadoop/eco_service/tez
export TEZ_CONF_DIR=${TEZ_HOME}/conf
export SPARK_HOME=/home/hadoop/eco_service/spark
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:${HADOOP_CONF_DIR}:${HADOOP_COMMON_HOME}/share/hadoop/common/*:${HADOOP_COMMON_HOME}/share/hadoop/common/lib/*:${HADOOP_MAPRED_HOME}/share/hadoop/mapreduce/*:${HADOOP_MAPRED_HOME}/share/hadoop/mapreduce/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*:${HADOOP_YARN_HOME}/share/hadoop/yarn/*:${HADOOP_YARN_HOME}/share/hadoop/yarn/lib/*:${TEZ_CONF_DIR}:${TEZ_HOME}/*:${TEZ_HOME}/lib/*:${SPARK_HOME}/yarn/*:$HADOOP_HOME/share/hadoop/tools/lib/*
```
</p>
</details>

#### start journalnode
`bin/hadoop-daemon.sh start journalnode`

#### format namenode
`hdfs namenode -format`

#### start hdfs(name, resourcemanager, datanode)
`sbin/start-all.sh`


## hive install
- apache hive-3.1.2 version

### hive 3.1.2 binary download
```
cd /home/hadoop/installed
wget http://apache.tt.co.kr/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz
tar -xvf apache-hive-3.1.2-bin.tar.gz
rm -rf apache-hive-3.1.2-bin.tar.gz
ln -s /home/hadoop/installed/apache-hive-3.1.2-bin /home/hadoop/eco_service/hive
```

### hive config
```
cp /home/hadoop/eco_service/hive/conf/hive-env.sh.template /home/hadoop/eco_service/hive/conf/hive-env.sh
cp /home/hadoop/eco_service/hive/conf/hive-default.xml.template /home/hadoop/eco_service/hive/conf/hive-site.xml
```

<details>
  <summary>hive-env.sh</summary>
  <p>

```
export HADOOP_HEAPSIZE=4096
# Set HADOOP_HOME to point to a specific hadoop install directory
HADOOP_HOME=${HADOOP_HOME}

# Hive Configuration Directory can be controlled by:
export HIVE_CONF_DIR=${HIVE_HOME}/conf

TEZ_INSTALL_DIR=/home/hadoop/eco_service/tez
TEZ_JARS=$(echo "$TEZ_INSTALL_DIR"/*.jar | tr ' ' ':'):$(echo "$TEZ_INSTALL_DIR"/lib/*.jar | tr ' ' ':')
```
</p>
</details>

<details>
  <summary>hive-site.xml</summary>
  <p>

```
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?><!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
--><configuration>
  <!-- WARNING!!! This file is auto generated for documentation purposes ONLY! -->
  <!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   -->
  <!-- WARNING!!! You must make your changes in hive-site.xml instead.         -->
  <!-- Hive Execution Parameters -->
    <!--property>
        <name>hive.metastore.local</name>
        <value>false</value>
    </property-->

    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://{host}:{port}/{database_name}?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=UTF-8</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.cj.jdbc.Driver</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>{db_user}</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>{db_password}</value>
    </property>

    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://host-nn-001-02:9083</value>
    </property>

    <property>
         <name>hive.metastore.connect.retries</name>
         <value>30</value>
    </property>

     <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>host-nn-001-02</value>
    </property>

     <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
    </property>

     <property>
        <name>hive.server2.thrift.min.worker.threads</name>
        <value>5</value>
    </property>

     <property>
        <name>hive.server2.thrift.max.worker.threads</name>
        <value>500</value>
    </property>

    <property>
        <name>hive.server2.enable.doAs</name>
        <value>false</value>
    </property>

    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
        <description>
        Local or HDFS directory where Hive keeps table contents.
        </description>
    </property>

    <!--property>
        <name>hive.server2.authentication</name>
        <value>NONE</value>
    </property-->

    <property>
        <name>hive.support.concurrency</name>
        <value>false</value>
    </property>


    <!--property>
        <name>hive.metastore.event.db.notification.api.auth</name>
        <value>true</value>
    </property-->


    <property>
            <name>hive.server2.webui.host</name>
        <value>host-nn-001-02</value>
    </property>

    <property>
        <name>hive.server2.webui.port</name>
        <value>10002</value>
    </property>

    <property>
        <name>hive.execution.engine</name>
        <value>tez</value>
    </property>

    <property>
        <name>hive.server2.idle.session.check.operation</name>
        <value>true</value>
    </property>

    <property>
        <name>hive.server2.session.check.interval</name>
        <value>6h</value>
    </property>


    <property>
        <name>hive.server2.idle.operation.timeout</name>
        <value>5d</value>
    </property>


    <property>
        <name>hive.server2.idle.session.timeout</name>
        <value>7d</value>
    </property>

    <property>
        <name>hive.metastore.client.socket.timeout</name>
        <value>1h</value>
        <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      MetaStore Client socket timeout in seconds
        </description>
    </property>

    <property>
        <name>hive.server2.tez.initialize.default.sessions</name>
        <value>true</value>
    </property>

    <property>
        <name>hive.tez.container.size</name>
        <value>2048</value>
    </property>

    <property>
        <name>hive.tez.java.opts</name>
        <value>-Xmx1640m</value>
    </property>

    <property>
        <name>tez.runtime.io.sort.mb</name>
        <value>800</value>
    </property>


  <property>
    <name>hive.vectorized.execution.enabled</name>
    <value>true</value>
    <description>
      This flag should be set to true to enable vectorized mode of query execution.
      The default value is true to reflect that our most expected Hive deployment will be using vectorization.
    </description>
  </property>
  <property>
    <name>hive.vectorized.execution.reduce.enabled</name>
    <value>true</value>
    <description>
      This flag should be set to true to enable vectorized mode of the reduce-side of query execution.
      The default value is true.
    </description>
  </property>
  <property>
    <name>hive.vectorized.execution.reduce.groupby.enabled</name>
    <value>true</value>
    <description>
      This flag should be set to true to enable vectorized mode of the reduce-side GROUP BY query execution.
      The default value is true.
    </description>
  </property>
  <property>
    <name>hive.vectorized.execution.mapjoin.native.enabled</name>
    <value>true</value>
    <description>
      This flag should be set to true to enable native (i.e. non-pass through) vectorization
      of queries using MapJoin.
      The default value is true.
    </description>
  </property>

  <property>
    <name>hive.cbo.enable</name>
    <value>true</value>
    <description>Flag to control enabling Cost Based Optimizations using Calcite framework.</description>
  </property>
    <property>
    <name>hive.compute.query.using.stats</name>
    <value>true</value>
    <description>
      When set to true Hive will answer a few queries like count(1) purely using stats
      stored in metastore. For basic stats collection turn on the config hive.stats.autogather to true.
      For more advanced stats collection need to run analyze table queries.
    </description>
  </property>
<property>
  <name>fs.s3a.access.key</name>
  <value>{access_key}</value>
  <description>AWS access key ID. Omit for Role-based authentication.</description>
</property>
<property>
  <name>fs.s3a.secret.key</name>
  <value>{secret_key}</value>
  <description>AWS secret key. Omit for Role-based authentication.</description>
</property>

</configuration>
```
</p>
</details>

### start metastore, hiveserver2
```
bin/hive service metastore &
bin/hive service hiveserver2 &
```

## tez install
### apache-tez 0.9.2 binary download
```
cd /home/hadoop/installed
wget http://apache.tt.co.kr/tez/0.9.2/apache-tez-0.9.2-bin.tar.gz
tar -xvf apache-tez-0.9.2-bin.tar.gz
rm -rf apache-tez-0.9.2-bin.tar.gz
ln -s /home/hadoop/installed/apache-tez-0.9.2-bin.tar.gz /home/hadoop/eco_service/tez
```

### tez config
```
vi /home/hadoop/eco_service/tez/tez-site.xml
```

<details>
  <summary>tez-site.xml</summary>
  <p>

```
<!--?xml version="1.0"?-->
<!--?xml-stylesheet type="text/xsl" href="configuration.xsl"?-->
<configuration>
  <property>
    <name>tez.lib.uris</name>
    <value>${fs.defaultFS}/apps/tez-0.9.2,${fs.defaultFS}/apps/tez-0.9.2/lib</value>
  </property>

  <property>
    <name>tez.lib.uris.classpath</name>
    <value>${fs.defaultFS}/apps/tez-0.9.2,${fs.defaultFS}/apps/tez-0.9.2/lib</value>
  </property>


  <property>
    <name>tez.use.cluster.hadoop-libs</name>
    <value>true</value>
  </property>
</configuration>
```
</p>
</details>

### upload tez tarball, tez-site.xml
```
hadoop fs -mkdir /apps
cd /home/hadoop/installed
hadoop fs -put tez-0.9.2 /apps
```

## spark install
### spark 2.4.4 binary download
```
cd /home/hadoop/installed
wget http://apache.tt.co.kr/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
tar -xvf spark-2.4.4-bin-hadoop2.7.tgz
rm -rf spark-2.4.4-bin-hadoop2.7.tgz
ln -s /home/hadoop/installed/spark-2.4.4-bin-hadoop2.7 /home/hadoop/eco_service/spark
```

### spark config
#### mysql connector download
```
cd /home/hadoop/eco_service/spark/jars
wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar
```

<details>
  <summary>spark-env.sh</summary>
  <p>

```
export SPARK_HOME=${SPARK_HOME:-/home/hadoop/eco_service/spark}
export YARN_CONF_DIR=${YARN_CONF_DIR:-${HADOOP_HOME}/etc/hadoop}
export HIVE_SERVER2_THRIFT_PORT=10001

export HADOOP_HOME=${HADOOP_HOME:-/home/hadoop/eco_service/hadoop}
export HADOOP_HDFS_HOME=${HADOOP_HDFS_HOME:-${HADOOP_HOME}}
export HADOOP_MAPRED_HOME=${HADOOP_MAPRED_HOME:-${HADOOP_HOME}}
export HADOOP_YARN_HOME=${HADOOP_YARN_HOME:-${HADOOP_HOME}}
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-/home/hadoop/eco_service/hadoop/etc/hadoop}

export STANDALONE_SPARK_MASTER_HOST=`hostname -f`
export SPARK_MASTER_PORT=7077
export SPARK_MASTER_WEBUI_PORT=8080

export SPARK_WORKER_DIR=${SPARK_WORKER_DIR:-/var/run/spark/work}
export SPARK_WORKER_PORT=7078
export SPARK_WORKER_WEBUI_PORT=18081

export SPARK_WORKER_DIR=${SPARK_WORKER_DIR:-/var/run/spark/work}
export SPARK_LOG_DIR=${SPARK_HOME}/logs

### change the following to specify a real cluster's Master host
export STANDALONE_SPARK_MASTER_HOST=\`hostname\`

SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_CONF_DIR"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_HOME/lib/native"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_HOME/lib/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_HOME/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_HDFS_HOME/lib/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_HDFS_HOME/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_MAPRED_HOME/lib/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_MAPRED_HOME/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_YARN_HOME/lib/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_YARN_HOME/*"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:/etc/hive/conf"
SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$HADOOP_HOME/share/tools/lib/*"
export PYSPARK_PYTHON=/usr/bin/python3
export PYSPARK_DRIVER_PYTHON=/usr/bin/python3
```
</p>
</details>

<details>
  <summary>spark-default.conf</summary>
  <p>

```
spark.master                     yarn
spark.submit.deployMode          client
spark.eventLog.enabled           true
spark.yarn.jars                  hdfs://host-cluster/user/oozie/share/lib/spark2/*
spark.eventLog.dir               hdfs://host-cluster/user/spark/eventlog
spark.history.fs.logDirectory    hdfs://host-cluster/user/spark/historylog
spark.serializer                 org.apache.spark.serializer.KryoSerializer
spark.driver.memory              1548m
spark.executor.memory            2048m
spark.memory.offHeap.enabled     true
spark.memory.offHeap.size        900m
spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dcom.amazonaws.services.s3.enableV4=true
spark.driver.extraJavaOptions  -XX:+PrintGCDetails -Dcom.amazonaws.services.s3.enableV4=true

#Dynamic allocation on YARN
spark.dynamicAllocation.enabled             true
spark.dynamicAllocation.minExecutors        1
spark.executor.instances                    100
spark.dynamicAllocation.maxExecutors        10000
spark.shuffle.service.enabled               true
spark.scheduler.minRegisteredResourcesRatio 0.0
spark.network.timeout 1000000
spark.sql.warehouse.dir=hdfs://host-cluster:8020/user/hive/warehouse

spark.yarn.historyServer.address            host-nn-001-02:18080

spark.hadoop.fs.s3a.access.key={access_key}
spark.hadoop.fs.s3a.endpoint=s3.{region}.amazonaws.com
spark.hadoop.fs.s3a.secret.key={secret_key}
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
```
</p>
</details>